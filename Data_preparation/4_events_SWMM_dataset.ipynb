{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cylJiaDMa8fI",
        "outputId": "aa86719e-52a0-42c1-fa3b-b1e9c6e10020"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/rainfall/201807_202306/events\n"
          ]
        }
      ],
      "source": [
        " from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/rainfall/201807_202306/events"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot all rainfall events for dataset"
      ],
      "metadata": {
        "id": "70iYjG0jWqGz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "import matplotlib.ticker as ticker\n",
        "from matplotlib.offsetbox import AnchoredText"
      ],
      "metadata": {
        "id": "B6-cSJm7Hr6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# file names extracted by 2_IETD_Inter-Event Time Definition\n",
        "file_names = ['2021/event64','2020/event37','2021/event29','2022/event38','2022/event51','2023/event15','2021/event41',\n",
        "              '2020/event60','2023/event8','2022/event6','2023/event1','2022/event31','2023/event16','2020/event67',\n",
        "              '2021/event19','2020/event55','2021/event25','2021/event22','2022/event27','2023/event19','2021/event37',\n",
        "              '2022/event28','2022/event26','2021/event7','2022/event47','2022/event36','2021/event5','2021/event46',\n",
        "              '2022/event34','2020/event61','2020/event69','2021/event50','2021/event12','2022/event29','2022/event46',\n",
        "              '2023/event4','2020/event36','2020/event49','2022/event8','2021/event31','2022/event33','2021/event32',\n",
        "              '2021/event56']\n",
        "\n",
        "fig, axs = plt.subplots(nrows=9, ncols=5, figsize=(15, 20))\n",
        "# plot all rainfall events\n",
        "for i, file in enumerate(file_names):\n",
        "    df = pd.read_csv(file + '.csv')\n",
        "    df['datetime'] = pd.to_datetime(df['DateAndTime'])\n",
        "    df.set_index('datetime', inplace=True)\n",
        "    df_5min = df.resample('5T').sum()\n",
        "    row = i // 5\n",
        "    col = i % 5\n",
        "    axs[row, col].plot(df_5min.index, df_5min['rainfall'])\n",
        "    axs[row, col].set_xlabel('Time')\n",
        "    axs[row, col].set_ylabel('Rainfall (mm)')\n",
        "    axs[row, col].set_title('Event i+1: '+ file, y = 1.2)\n",
        "    duration = (df_5min.index[-1] - df_5min.index[0]).total_seconds() / 3600  # calculate duration in hours\n",
        "    accumulation = df_5min['rainfall'].sum()  # calculate accumulation\n",
        "    intensity = accumulation / duration # calculate intensity (mm/hour)\n",
        "    axs[row, col].text(0.1, 1.12, f'D: {duration:.2f}h, I: {intensity:.2f} mm/h', transform=axs[row, col].transAxes, fontsize=10, verticalalignment='center')\n",
        "    # Set x-axis ticks and labels to show only the start value\n",
        "    #axs[row, col].set_xticks([df_5min.index[-1]])\n",
        "    axs[row, col].set_xticks([df_5min.index[len(df_5min.index) // 2]])\n",
        "    axs[row, col].set_xticklabels([df_5min.index[-1].strftime('%Y-%m-%d %H:%M')])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7q9wGy2SVi1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SWMM Simulation"
      ],
      "metadata": {
        "id": "tjF-gNJDMJwn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7YqsFJwhcpx"
      },
      "outputs": [],
      "source": [
        "!pip install swmm-api\n",
        "!pip install pyswmm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LIzXA9azPsT"
      },
      "outputs": [],
      "source": [
        "from swmm_api import read_inp_file\n",
        "from swmm_api import read_out_file\n",
        "from swmm_api import swmm5_run\n",
        "from swmm_api.input_file.sections import RainGage\n",
        "from swmm_api.input_file.sections import OptionSection\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_names = ['2021/event64','2020/event37','2021/event29','2022/event38','2022/event51','2023/event15','2021/event41',\n",
        "              '2020/event60','2023/event8','2022/event6','2023/event1','2022/event31','2023/event16','2020/event67',\n",
        "              '2021/event19','2020/event55','2021/event25','2021/event22','2022/event27','2023/event19','2021/event37',\n",
        "              '2022/event28','2022/event26','2021/event7','2022/event47','2022/event36','2021/event5','2021/event46',\n",
        "              '2022/event34','2020/event61','2020/event69','2021/event50','2021/event12','2022/event29','2022/event46',\n",
        "              '2023/event4','2020/event36','2020/event49','2022/event8','2021/event31','2022/event33','2021/event32',\n",
        "              '2021/event56']\n",
        "\n",
        "for file in file_names:\n",
        "    df = pd.read_csv(file + '.csv')\n",
        "    df[\"DateAndTime\"] = pd.to_datetime(df[\"DateAndTime\"])\n",
        "    df = df.assign(\n",
        "        year=df[\"DateAndTime\"].dt.year,\n",
        "        month=df[\"DateAndTime\"].dt.month,\n",
        "        day=df[\"DateAndTime\"].dt.day,\n",
        "        hour=df[\"DateAndTime\"].dt.hour,\n",
        "        minute=df[\"DateAndTime\"].dt.minute,\n",
        "        date = df[\"DateAndTime\"].dt.date,\n",
        "        time = df[\"DateAndTime\"].dt.time,\n",
        "    )\n",
        "    df[\"station\"]=\"STA01\"\n",
        "    newdf = pd.DataFrame(df[['station', 'year', 'month', 'day', 'hour', 'minute','rainfall']])\n",
        "    newdf.to_csv(file + '.dat', sep = \"\\t\",index=None,header=None)\n",
        "\n",
        "    # set start and end time\n",
        "    start_datetime = df['DateAndTime'].iloc[0] - datetime.timedelta(minutes=60)\n",
        "    start_date = start_datetime.date()\n",
        "    strat_time = start_datetime.time()\n",
        "    end_date = df['date'].iloc[-1]\n",
        "    end_time = df['time'].iloc[-1]\n",
        "\n",
        "\n",
        "    # creat an inp. file in SWMM software with network data, 3 year climate data as a baseline\n",
        "    # read this inp file, only change rainfall for following simulations\n",
        "    inp = read_inp_file('in_8.9.inp')\n",
        "\n",
        "\n",
        "    # edit raingage and change rainfall files\n",
        "    inp.RAINGAGES['STA01'] = RainGage(name='STA01', form='VOLUME', interval='0:01', SCF=1.0, source='FILE', filename='/content/drive/MyDrive/rainfall/201807_202306/events/'+ file + '.dat',  station='STA01', units='MM')\n",
        "\n",
        "\n",
        "    # edit running options and change time\n",
        "    inp.OPTIONS['START_DATE'] = start_date\n",
        "    inp.OPTIONS['START_TIME'] = strat_time\n",
        "    inp.OPTIONS['REPORT_START_DATE'] = start_date\n",
        "    inp.OPTIONS['REPORT_START_TIME'] = strat_time\n",
        "    inp.OPTIONS['END_DATE'] = end_date\n",
        "    inp.OPTIONS['END_TIME'] = end_time\n",
        "    print(inp.OPTIONS.to_inp_lines())\n",
        "\n",
        "\n",
        "    #write to a new inp file and run it\n",
        "    inp.write_file(file + '.inp')\n",
        "    swmm5_run('/content/drive/MyDrive/rainfall/201807_202306/events/'+ file +'.inp', progress_size=100)\n"
      ],
      "metadata": {
        "id": "d0_6OKEBJujf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Training Data"
      ],
      "metadata": {
        "id": "nt0dWFQrMRiG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXUd-6Hq5mTo"
      },
      "outputs": [],
      "source": [
        "def generate_data(raindata_masked, seq_length_x, seq_length_y, y_start):\n",
        "    df_data = raindata_masked.iloc[:,1:]\n",
        "    df_rain = raindata_masked.iloc[:,:1]\n",
        "    num_samples, num_nodes = df_data.shape\n",
        "    data = np.expand_dims(df_data.values, axis=-1)\n",
        "    feature_list = [data]\n",
        "    rain = df_rain.iloc[:,0]\n",
        "    rainfall = np.tile(rain, [1, num_nodes, 1]).transpose((2, 1, 0))\n",
        "    feature_list.append(rainfall)\n",
        "    data = np.concatenate(feature_list, axis=-1)\n",
        "    x, y = [], []\n",
        "    min_t = abs(min(x_offsets))\n",
        "    max_t = abs(num_samples - abs(max(y_offsets)))\n",
        "    for t in range(min_t, max_t):\n",
        "        x.append(data[t + x_offsets, ...])\n",
        "        y.append(data[t + y_offsets, ...])\n",
        "    x = np.stack(x, axis=0)\n",
        "    y = np.stack(y, axis=0)\n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zQX3C_LeVMr"
      },
      "outputs": [],
      "source": [
        "def concat_shuffle_writeintonpz_data(outx, outy, save_dir):\n",
        "    x_con = np.concatenate(outx, axis=0)\n",
        "    y_con = np.concatenate(outy, axis=0)\n",
        "    permutation = np.random.permutation(x_con.shape[0])\n",
        "    x_data = x_con[permutation]\n",
        "    y_data = y_con[permutation]\n",
        "    num_samples = x_data.shape[0]\n",
        "    num_val = round(num_samples * 0.15)\n",
        "    num_train = round(num_samples * 0.7)\n",
        "    #num_test = round(num_samples * 0.15)# the number of test sample should be the same for different input length, so we dont use this line\n",
        "    num_test = round(599) # this line assign same number of test sample for all input length, 599 is the test sample created by the largest input length, which is a minimum\n",
        "    x_train, y_train = x_data[:num_train], y_data[:num_train]\n",
        "    x_val, y_val = (\n",
        "        x_data[num_train: num_train + num_val],\n",
        "        y_data[num_train: num_train + num_val],\n",
        "    )\n",
        "    x_test, y_test = x_data[-num_test:], y_data[-num_test:]\n",
        "    for cat in [\"train\", \"val\", \"test\"]:\n",
        "        _x, _y = locals()[\"x_\" + cat], locals()[\"y_\" + cat]\n",
        "        print(cat, \"x:\", _x.shape, \"y:\", _y.shape)\n",
        "        file_path = os.path.join(save_dir, f\"{cat}.npz\")\n",
        "        np.savez_compressed(\n",
        "            file_path,\n",
        "            x=_x,\n",
        "            y=_y,\n",
        "            x_offsets=x_offsets.reshape(list(x_offsets.shape) + [1]),\n",
        "            y_offsets=y_offsets.reshape(list(y_offsets.shape) + [1]),\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wyGVLSz1Jv6l"
      },
      "outputs": [],
      "source": [
        "seq_lengths = [(6, 6), (7, 6), (8, 6), (9, 6),(10, 6), (11, 6),(12, 6), (13, 6),(14, 6)]\n",
        "\n",
        "for seq_length_x, seq_length_y in seq_lengths:\n",
        "    y_start = 1\n",
        "    x_offsets = np.sort(np.concatenate((np.arange(-(seq_length_x - 1), 1, 1),)))\n",
        "    y_offsets = np.sort(np.arange(y_start, (seq_length_y + 1), 1))\n",
        "\n",
        "    save_dir_link = \"/content/drive/MyDrive/0809/link/\"+\"link_flow_len\" + str(seq_length_x) +\"_\" + str(seq_length_y) +\"_f_r\"\n",
        "    save_dir_node = \"/content/drive/MyDrive/0809/node/\"+\"node_flow_len\" + str(seq_length_x) +\"_\" + str(seq_length_y) +\"_f_r\"\n",
        "    save_dir_cap = \"/content/drive/MyDrive/0809/cap/\"+\"link_cap_len\" + str(seq_length_x) +\"_\" + str(seq_length_y) +\"_f_r\"\n",
        "    os.makedirs(save_dir_link)\n",
        "    os.makedirs(save_dir_node)\n",
        "    os.makedirs(save_dir_cap)\n",
        "\n",
        "    outx_node=[]\n",
        "    outy_node=[]\n",
        "    outx_link=[]\n",
        "    outy_link=[]\n",
        "    outx_cap=[]\n",
        "    outy_cap=[]\n",
        "\n",
        "    file_names = ['2021/event64','2020/event37','2021/event29','2022/event38','2022/event51','2023/event15','2021/event41',\n",
        "                  '2020/event60','2023/event8','2022/event6','2023/event1','2022/event31','2023/event16','2020/event67',\n",
        "                  '2021/event19','2020/event55','2021/event25','2021/event22','2022/event27','2023/event19','2021/event37',\n",
        "                  '2022/event28','2022/event26','2021/event7','2022/event47','2022/event36','2021/event5','2021/event46',\n",
        "                  '2022/event34','2020/event61','2020/event69','2021/event50','2021/event12','2022/event29','2022/event46',\n",
        "                  '2023/event4','2020/event36','2020/event49','2022/event8','2021/event31','2022/event33','2021/event32',\n",
        "                  '2021/event56']\n",
        "\n",
        "    for file in file_names:\n",
        "    # read out file\n",
        "        out = read_out_file('/content/drive/MyDrive/rainfall/201807_202306/events/'+file +'.out')\n",
        "        type(out.to_numpy())\n",
        "        out.to_frame()\n",
        "\n",
        "    # extract rainfall, node, link,cap and concat them\n",
        "        rainfall = out.get_part('system', '', 'rainfall')\n",
        "        node = out.get_part('node',out.labels['node'],'total_inflow')\n",
        "        link = out.get_part('link',out.labels['link'],'flow')\n",
        "        cap = out.get_part('link',out.labels['link'],'capacity')\n",
        "        rainnode = pd.concat([rainfall, node], axis=1)\n",
        "        rainlink = pd.concat([rainfall, link], axis=1)\n",
        "        raincap = pd.concat([rainfall, cap], axis=1)\n",
        "\n",
        "    # make two masks to drop flow = 0 at start and rainfall = 0 at the end\n",
        "        masknode = (rainnode.iloc[:, 1:2] == 0).all(axis=1)\n",
        "        start = masknode.loc[~masknode].index[0]\n",
        "        maskrain = (rainnode.iloc[:, 0:1] == 0).all(axis=1)\n",
        "        end = maskrain.loc[~maskrain].index[-1]\n",
        "        mask = (rainnode.index < start) | (rainnode.index > end)\n",
        "        rainnode_masked = rainnode.loc[~mask]\n",
        "        rainlink_masked = rainlink.loc[~mask]\n",
        "        raincap_masked = raincap.loc[~mask]\n",
        "\n",
        "    # process and append data\n",
        "        rainnode_x, rainnode_y = generate_data(rainnode_masked, seq_length_x, seq_length_y, y_start)\n",
        "        rainlink_x, rainlink_y = generate_data(rainlink_masked, seq_length_x, seq_length_y, y_start)\n",
        "        raincap_x, raincap_y = generate_data(raincap_masked, seq_length_x, seq_length_y, y_start)\n",
        "        outx_node.append(rainnode_x)\n",
        "        outy_node.append(rainnode_y)\n",
        "        outx_link.append(rainlink_x)\n",
        "        outy_link.append(rainlink_y)\n",
        "        outx_cap.append(raincap_x)\n",
        "        outy_cap.append(raincap_y)\n",
        "\n",
        "    concat_shuffle_writeintonpz_data(outx_node, outy_node, save_dir_node)\n",
        "    concat_shuffle_writeintonpz_data(outx_link, outy_link, save_dir_link)\n",
        "    concat_shuffle_writeintonpz_data(outx_cap, outy_cap, save_dir_cap)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}