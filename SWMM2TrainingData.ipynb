{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cylJiaDMa8fI",
        "outputId": "e4126316-ab92-4ca0-e6c6-0d734c6d8f0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/GWN-Project\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/GWN-Project"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "import numpy as np\n",
        "import os"
      ],
      "metadata": {
        "id": "B6-cSJm7Hr6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXUd-6Hq5mTo"
      },
      "outputs": [],
      "source": [
        "def generate_data(raindata_masked, seq_length_x, seq_length_y, y_start):\n",
        "    df_data = raindata_masked.iloc[:,1:]\n",
        "    df_rain = raindata_masked.iloc[:,:1]\n",
        "    num_samples, num_nodes = df_data.shape\n",
        "    data = np.expand_dims(df_data.values, axis=-1)\n",
        "    feature_list = [data]\n",
        "    rain = df_rain.iloc[:,0]\n",
        "    rainfall = np.tile(rain, [1, num_nodes, 1]).transpose((2, 1, 0))\n",
        "    feature_list.append(rainfall)\n",
        "    data = np.concatenate(feature_list, axis=-1)\n",
        "    x, y = [], []\n",
        "    min_t = abs(min(x_offsets))\n",
        "    max_t = abs(num_samples - abs(max(y_offsets)))\n",
        "    for t in range(min_t, max_t):\n",
        "        x.append(data[t + x_offsets, ...])\n",
        "        y.append(data[t + y_offsets, ...])\n",
        "    x = np.stack(x, axis=0)\n",
        "    y = np.stack(y, axis=0)\n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zQX3C_LeVMr"
      },
      "outputs": [],
      "source": [
        "def concat_shuffle_writeintonpz_data(outx, outy, save_dir):\n",
        "    x_con = np.concatenate(outx, axis=0)\n",
        "    y_con = np.concatenate(outy, axis=0)\n",
        "    permutation = np.random.permutation(x_con.shape[0])\n",
        "    x_data = x_con[permutation]\n",
        "    y_data = y_con[permutation]\n",
        "    num_samples = x_data.shape[0]\n",
        "    num_val = round(num_samples * 0.15)\n",
        "    num_train = round(num_samples * 0.7)\n",
        "    #num_test = round(num_samples * 0.15)# the number of test sample should be the same for different input length, so we dont use this line\n",
        "    num_test = round(599) # this line assign same number of test sample for all input length, 599 is the test sample created by the largest input length, which is a minimum\n",
        "    x_train, y_train = x_data[:num_train], y_data[:num_train]\n",
        "    x_val, y_val = (\n",
        "        x_data[num_train: num_train + num_val],\n",
        "        y_data[num_train: num_train + num_val],\n",
        "    )\n",
        "    x_test, y_test = x_data[-num_test:], y_data[-num_test:]\n",
        "    for cat in [\"train\", \"val\", \"test\"]:\n",
        "        _x, _y = locals()[\"x_\" + cat], locals()[\"y_\" + cat]\n",
        "        print(cat, \"x:\", _x.shape, \"y:\", _y.shape)\n",
        "        file_path = os.path.join(save_dir, f\"{cat}.npz\")\n",
        "        np.savez_compressed(\n",
        "            file_path,\n",
        "            x=_x,\n",
        "            y=_y,\n",
        "            x_offsets=x_offsets.reshape(list(x_offsets.shape) + [1]),\n",
        "            y_offsets=y_offsets.reshape(list(y_offsets.shape) + [1]),\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wyGVLSz1Jv6l"
      },
      "outputs": [],
      "source": [
        "seq_lengths = [(6, 6), (7, 6), (8, 6), (9, 6),(10, 6), (11, 6),(12, 6)]\n",
        "\n",
        "for seq_length_x, seq_length_y in seq_lengths:\n",
        "    y_start = 1\n",
        "    x_offsets = np.sort(np.concatenate((np.arange(-(seq_length_x - 1), 1, 1),)))\n",
        "    y_offsets = np.sort(np.arange(y_start, (seq_length_y + 1), 1))\n",
        "\n",
        "    save_dir_link = \"/content/drive/MyDrive/GWN-Project/dataset/link/\"+\"link_flow_len\" + str(seq_length_x) +\"_\" + str(seq_length_y) +\"_f_r\"\n",
        "    save_dir_node = \"/content/drive/MyDrive/GWN-Project/dataset/node/\"+\"node_flow_len\" + str(seq_length_x) +\"_\" + str(seq_length_y) +\"_f_r\"\n",
        "    save_dir_cap = \"/content/drive/MyDrive/GWN-Project/dataset/cap/\"+\"link_cap_len\" + str(seq_length_x) +\"_\" + str(seq_length_y) +\"_f_r\"\n",
        "    os.makedirs(save_dir_link)\n",
        "    os.makedirs(save_dir_node)\n",
        "    os.makedirs(save_dir_cap)\n",
        "\n",
        "    outx_node=[]\n",
        "    outy_node=[]\n",
        "    outx_link=[]\n",
        "    outy_link=[]\n",
        "    outx_cap=[]\n",
        "    outy_cap=[]\n",
        "\n",
        "    file_names = ['2021/event64','2020/event37','2021/event29','2022/event38','2022/event51','2023/event15','2021/event41',\n",
        "                  '2020/event60','2023/event8','2022/event6','2023/event1','2022/event31','2023/event16','2020/event67',\n",
        "                  '2021/event19','2020/event55','2021/event25','2021/event22','2022/event27','2023/event19','2021/event37',\n",
        "                  '2022/event28','2022/event26','2021/event7','2022/event47','2022/event36','2021/event5','2021/event46',\n",
        "                  '2022/event34','2020/event61','2020/event69','2021/event50','2021/event12','2022/event29','2022/event46',\n",
        "                  '2023/event4','2020/event36','2020/event49','2022/event8','2021/event31','2022/event33','2021/event32',\n",
        "                  '2021/event56']\n",
        "\n",
        "    for file in file_names:\n",
        "    # read SWMM output file\n",
        "        out = read_out_file('/content/drive/MyDrive/GWN-Project/events/'+file +'.out')\n",
        "        type(out.to_numpy())\n",
        "        out.to_frame()\n",
        "\n",
        "    # extract rainfall, node, link,cap and concat them\n",
        "        rainfall = out.get_part('system', '', 'rainfall')\n",
        "        node = out.get_part('node',out.labels['node'],'total_inflow')\n",
        "        link = out.get_part('link',out.labels['link'],'flow')\n",
        "        cap = out.get_part('link',out.labels['link'],'capacity')\n",
        "        rainnode = pd.concat([rainfall, node], axis=1)\n",
        "        rainlink = pd.concat([rainfall, link], axis=1)\n",
        "        raincap = pd.concat([rainfall, cap], axis=1)\n",
        "\n",
        "    # make two masks to drop flow = 0 at start and rainfall = 0 at the end\n",
        "        masknode = (rainnode.iloc[:, 1:2] == 0).all(axis=1)\n",
        "        start = masknode.loc[~masknode].index[0]\n",
        "        maskrain = (rainnode.iloc[:, 0:1] == 0).all(axis=1)\n",
        "        end = maskrain.loc[~maskrain].index[-1]\n",
        "        mask = (rainnode.index < start) | (rainnode.index > end)\n",
        "        rainnode_masked = rainnode.loc[~mask]\n",
        "        rainlink_masked = rainlink.loc[~mask]\n",
        "        raincap_masked = raincap.loc[~mask]\n",
        "\n",
        "    # process and append data\n",
        "        rainnode_x, rainnode_y = generate_data(rainnode_masked, seq_length_x, seq_length_y, y_start)\n",
        "        rainlink_x, rainlink_y = generate_data(rainlink_masked, seq_length_x, seq_length_y, y_start)\n",
        "        raincap_x, raincap_y = generate_data(raincap_masked, seq_length_x, seq_length_y, y_start)\n",
        "        outx_node.append(rainnode_x)\n",
        "        outy_node.append(rainnode_y)\n",
        "        outx_link.append(rainlink_x)\n",
        "        outy_link.append(rainlink_y)\n",
        "        outx_cap.append(raincap_x)\n",
        "        outy_cap.append(raincap_y)\n",
        "\n",
        "    concat_shuffle_writeintonpz_data(outx_node, outy_node, save_dir_node)\n",
        "    concat_shuffle_writeintonpz_data(outx_link, outy_link, save_dir_link)\n",
        "    concat_shuffle_writeintonpz_data(outx_cap, outy_cap, save_dir_cap)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}