{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cylJiaDMa8fI","outputId":"e4126316-ab92-4ca0-e6c6-0d734c6d8f0e","executionInfo":{"status":"ok","timestamp":1716040492524,"user_tz":-480,"elapsed":22326,"user":{"displayName":"Zhongming Lu","userId":"17616017109863297465"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/GWN-Project\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/GWN-Project"]},{"cell_type":"markdown","source":["## Plot all rainfall events for dataset"],"metadata":{"id":"70iYjG0jWqGz"}},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import matplotlib.dates as mdates\n","import matplotlib.ticker as ticker\n","from matplotlib.offsetbox import AnchoredText"],"metadata":{"id":"B6-cSJm7Hr6j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# file names extracted by 2_IETD_Inter-Event Time Definition\n","file_names = ['2021/event64','2020/event37','2021/event29','2022/event38','2022/event51','2023/event15','2021/event41',\n","              '2020/event60','2023/event8','2022/event6','2023/event1','2022/event31','2023/event16','2020/event67',\n","              '2021/event19','2020/event55','2021/event25','2021/event22','2022/event27','2023/event19','2021/event37',\n","              '2022/event28','2022/event26','2021/event7','2022/event47','2022/event36','2021/event5','2021/event46',\n","              '2022/event34','2020/event61','2020/event69','2021/event50','2021/event12','2022/event29','2022/event46',\n","              '2023/event4','2020/event36','2020/event49','2022/event8','2021/event31','2022/event33','2021/event32',\n","              '2021/event56']\n","\n","fig, axs = plt.subplots(nrows=9, ncols=5, figsize=(15, 20))\n","# plot all rainfall events\n","for i, file in enumerate(file_names):\n","    df = pd.read_csv(file + '.csv')\n","    df['datetime'] = pd.to_datetime(df['DateAndTime'])\n","    df.set_index('datetime', inplace=True)\n","    df_5min = df.resample('5T').sum()\n","    row = i // 5\n","    col = i % 5\n","    axs[row, col].plot(df_5min.index, df_5min['rainfall'])\n","    axs[row, col].set_xlabel('Time')\n","    axs[row, col].set_ylabel('Rainfall (mm)')\n","    axs[row, col].set_title('Event i+1: '+ file, y = 1.2)\n","    duration = (df_5min.index[-1] - df_5min.index[0]).total_seconds() / 3600  # calculate duration in hours\n","    accumulation = df_5min['rainfall'].sum()  # calculate accumulation\n","    intensity = accumulation / duration # calculate intensity (mm/hour)\n","    axs[row, col].text(0.1, 1.12, f'D: {duration:.2f}h, I: {intensity:.2f} mm/h', transform=axs[row, col].transAxes, fontsize=10, verticalalignment='center')\n","    # Set x-axis ticks and labels to show only the start value\n","    #axs[row, col].set_xticks([df_5min.index[-1]])\n","    axs[row, col].set_xticks([df_5min.index[len(df_5min.index) // 2]])\n","    axs[row, col].set_xticklabels([df_5min.index[-1].strftime('%Y-%m-%d %H:%M')])\n","\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"7q9wGy2SVi1P"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##SWMM Simulation"],"metadata":{"id":"tjF-gNJDMJwn"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"r7YqsFJwhcpx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716040521990,"user_tz":-480,"elapsed":17726,"user":{"displayName":"Zhongming Lu","userId":"17616017109863297465"}},"outputId":"9eaa6d16-4636-463f-94bf-28f276bc4f48"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting swmm-api\n","  Downloading swmm_api-0.4.42-py3-none-any.whl (295 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/295.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.1/295.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.2/295.2 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from swmm-api) (2.0.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from swmm-api) (4.66.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->swmm-api) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->swmm-api) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->swmm-api) (2024.1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas->swmm-api) (1.25.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->swmm-api) (1.16.0)\n","Installing collected packages: swmm-api\n","Successfully installed swmm-api-0.4.42\n","Collecting pyswmm\n","  Downloading pyswmm-2.0.1-py3-none-any.whl (111 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.8/111.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting swmm-toolkit>=0.9.0 (from pyswmm)\n","  Downloading swmm_toolkit-0.15.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (489 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.1/489.1 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting julian>=0.14 (from pyswmm)\n","  Downloading julian-0.14.zip (2.8 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting aenum>=3.1.11 (from pyswmm)\n","  Downloading aenum-3.1.15-py3-none-any.whl (137 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pyswmm) (24.0)\n","  Downloading aenum-3.1.11-py3-none-any.whl (131 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.5/131.5 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: julian\n","  Building wheel for julian (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for julian: filename=julian-0.14-py3-none-any.whl size=2612 sha256=f86348a5db8ce168086d94504120d358efd25a403cd23ea479d185d7fbc4afa4\n","  Stored in directory: /root/.cache/pip/wheels/03/10/8c/d2e9275374f869cd79f9f19f251876f97272f0c4ce60e3a053\n","Successfully built julian\n","Installing collected packages: julian, aenum, swmm-toolkit, pyswmm\n","Successfully installed aenum-3.1.11 julian-0.14 pyswmm-2.0.1 swmm-toolkit-0.15.5\n"]}],"source":["!pip install swmm-api\n","!pip install pyswmm"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"_LIzXA9azPsT","executionInfo":{"status":"ok","timestamp":1716040535332,"user_tz":-480,"elapsed":1452,"user":{"displayName":"Zhongming Lu","userId":"17616017109863297465"}}},"outputs":[],"source":["from swmm_api import read_inp_file\n","from swmm_api import read_out_file\n","from swmm_api import swmm5_run\n","from swmm_api.input_file.sections import RainGage\n","from swmm_api.input_file.sections import OptionSection\n","import pandas as pd\n","import datetime\n","import numpy as np\n","import os"]},{"cell_type":"code","source":["file_names = ['2021/event64','2020/event37','2021/event29','2022/event38','2022/event51','2023/event15','2021/event41',\n","              '2020/event60','2023/event8','2022/event6','2023/event1','2022/event31','2023/event16','2020/event67',\n","              '2021/event19','2020/event55','2021/event25','2021/event22','2022/event27','2023/event19','2021/event37',\n","              '2022/event28','2022/event26','2021/event7','2022/event47','2022/event36','2021/event5','2021/event46',\n","              '2022/event34','2020/event61','2020/event69','2021/event50','2021/event12','2022/event29','2022/event46',\n","              '2023/event4','2020/event36','2020/event49','2022/event8','2021/event31','2022/event33','2021/event32',\n","              '2021/event56']\n","\n","for file in file_names:\n","    df = pd.read_csv(file + '.csv')\n","    df[\"DateAndTime\"] = pd.to_datetime(df[\"DateAndTime\"])\n","    df = df.assign(\n","        year=df[\"DateAndTime\"].dt.year,\n","        month=df[\"DateAndTime\"].dt.month,\n","        day=df[\"DateAndTime\"].dt.day,\n","        hour=df[\"DateAndTime\"].dt.hour,\n","        minute=df[\"DateAndTime\"].dt.minute,\n","        date = df[\"DateAndTime\"].dt.date,\n","        time = df[\"DateAndTime\"].dt.time,\n","    )\n","    df[\"station\"]=\"STA01\"\n","    newdf = pd.DataFrame(df[['station', 'year', 'month', 'day', 'hour', 'minute','rainfall']])\n","    newdf.to_csv(file + '.dat', sep = \"\\t\",index=None,header=None)\n","\n","    # set start and end time\n","    start_datetime = df['DateAndTime'].iloc[0] - datetime.timedelta(minutes=60)\n","    start_date = start_datetime.date()\n","    strat_time = start_datetime.time()\n","    end_date = df['date'].iloc[-1]\n","    end_time = df['time'].iloc[-1]\n","\n","\n","    # creat an inp. file in SWMM software with network data, 3 year climate data as a baseline\n","    # read this inp file, only change rainfall for following simulations\n","    inp = read_inp_file('in_8.9.inp')\n","\n","\n","    # edit raingage and change rainfall files\n","    inp.RAINGAGES['STA01'] = RainGage(name='STA01', form='VOLUME', interval='0:01', SCF=1.0, source='FILE', filename='/content/drive/MyDrive/rainfall/201807_202306/events/'+ file + '.dat',  station='STA01', units='MM')\n","\n","\n","    # edit running options and change time\n","    inp.OPTIONS['START_DATE'] = start_date\n","    inp.OPTIONS['START_TIME'] = strat_time\n","    inp.OPTIONS['REPORT_START_DATE'] = start_date\n","    inp.OPTIONS['REPORT_START_TIME'] = strat_time\n","    inp.OPTIONS['END_DATE'] = end_date\n","    inp.OPTIONS['END_TIME'] = end_time\n","    print(inp.OPTIONS.to_inp_lines())\n","\n","\n","    #write to a new inp file and run it\n","    inp.write_file(file + '.inp')\n","    swmm5_run('/content/drive/MyDrive/rainfall/201807_202306/events/'+ file +'.inp', progress_size=100)\n"],"metadata":{"id":"d0_6OKEBJujf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Generate Training Data"],"metadata":{"id":"nt0dWFQrMRiG"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"FXUd-6Hq5mTo"},"outputs":[],"source":["def generate_data(raindata_masked, seq_length_x, seq_length_y, y_start):\n","    df_data = raindata_masked.iloc[:,1:]\n","    df_rain = raindata_masked.iloc[:,:1]\n","    num_samples, num_nodes = df_data.shape\n","    data = np.expand_dims(df_data.values, axis=-1)\n","    feature_list = [data]\n","    rain = df_rain.iloc[:,0]\n","    rainfall = np.tile(rain, [1, num_nodes, 1]).transpose((2, 1, 0))\n","    feature_list.append(rainfall)\n","    data = np.concatenate(feature_list, axis=-1)\n","    x, y = [], []\n","    min_t = abs(min(x_offsets))\n","    max_t = abs(num_samples - abs(max(y_offsets)))\n","    for t in range(min_t, max_t):\n","        x.append(data[t + x_offsets, ...])\n","        y.append(data[t + y_offsets, ...])\n","    x = np.stack(x, axis=0)\n","    y = np.stack(y, axis=0)\n","    return x, y"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0zQX3C_LeVMr"},"outputs":[],"source":["def concat_shuffle_writeintonpz_data(outx, outy, save_dir):\n","    x_con = np.concatenate(outx, axis=0)\n","    y_con = np.concatenate(outy, axis=0)\n","    permutation = np.random.permutation(x_con.shape[0])\n","    x_data = x_con[permutation]\n","    y_data = y_con[permutation]\n","    num_samples = x_data.shape[0]\n","    num_val = round(num_samples * 0.15)\n","    num_train = round(num_samples * 0.7)\n","    #num_test = round(num_samples * 0.15)# the number of test sample should be the same for different input length, so we dont use this line\n","    num_test = round(599) # this line assign same number of test sample for all input length, 599 is the test sample created by the largest input length, which is a minimum\n","    x_train, y_train = x_data[:num_train], y_data[:num_train]\n","    x_val, y_val = (\n","        x_data[num_train: num_train + num_val],\n","        y_data[num_train: num_train + num_val],\n","    )\n","    x_test, y_test = x_data[-num_test:], y_data[-num_test:]\n","    for cat in [\"train\", \"val\", \"test\"]:\n","        _x, _y = locals()[\"x_\" + cat], locals()[\"y_\" + cat]\n","        print(cat, \"x:\", _x.shape, \"y:\", _y.shape)\n","        file_path = os.path.join(save_dir, f\"{cat}.npz\")\n","        np.savez_compressed(\n","            file_path,\n","            x=_x,\n","            y=_y,\n","            x_offsets=x_offsets.reshape(list(x_offsets.shape) + [1]),\n","            y_offsets=y_offsets.reshape(list(y_offsets.shape) + [1]),\n","        )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wyGVLSz1Jv6l"},"outputs":[],"source":["seq_lengths = [(6, 6), (7, 6), (8, 6), (9, 6),(10, 6), (11, 6),(12, 6), (13, 6),(14, 6)]\n","\n","for seq_length_x, seq_length_y in seq_lengths:\n","    y_start = 1\n","    x_offsets = np.sort(np.concatenate((np.arange(-(seq_length_x - 1), 1, 1),)))\n","    y_offsets = np.sort(np.arange(y_start, (seq_length_y + 1), 1))\n","\n","    save_dir_link = \"/content/drive/MyDrive/GWN-Project/dataset/link/\"+\"link_flow_len\" + str(seq_length_x) +\"_\" + str(seq_length_y) +\"_f_r\"\n","    save_dir_node = \"/content/drive/MyDrive/GWN-Project/dataset/node/\"+\"node_flow_len\" + str(seq_length_x) +\"_\" + str(seq_length_y) +\"_f_r\"\n","    save_dir_cap = \"/content/drive/MyDrive/GWN-Project/dataset/cap/\"+\"link_cap_len\" + str(seq_length_x) +\"_\" + str(seq_length_y) +\"_f_r\"\n","    os.makedirs(save_dir_link)\n","    os.makedirs(save_dir_node)\n","    os.makedirs(save_dir_cap)\n","\n","    outx_node=[]\n","    outy_node=[]\n","    outx_link=[]\n","    outy_link=[]\n","    outx_cap=[]\n","    outy_cap=[]\n","\n","    file_names = ['2021/event64','2020/event37','2021/event29','2022/event38','2022/event51','2023/event15','2021/event41',\n","                  '2020/event60','2023/event8','2022/event6','2023/event1','2022/event31','2023/event16','2020/event67',\n","                  '2021/event19','2020/event55','2021/event25','2021/event22','2022/event27','2023/event19','2021/event37',\n","                  '2022/event28','2022/event26','2021/event7','2022/event47','2022/event36','2021/event5','2021/event46',\n","                  '2022/event34','2020/event61','2020/event69','2021/event50','2021/event12','2022/event29','2022/event46',\n","                  '2023/event4','2020/event36','2020/event49','2022/event8','2021/event31','2022/event33','2021/event32',\n","                  '2021/event56']\n","\n","    for file in file_names:\n","    # read out file\n","        out = read_out_file('/content/drive/MyDrive/GWN-Project/events/'+file +'.out')\n","        type(out.to_numpy())\n","        out.to_frame()\n","\n","    # extract rainfall, node, link,cap and concat them\n","        rainfall = out.get_part('system', '', 'rainfall')\n","        node = out.get_part('node',out.labels['node'],'total_inflow')\n","        link = out.get_part('link',out.labels['link'],'flow')\n","        cap = out.get_part('link',out.labels['link'],'capacity')\n","        rainnode = pd.concat([rainfall, node], axis=1)\n","        rainlink = pd.concat([rainfall, link], axis=1)\n","        raincap = pd.concat([rainfall, cap], axis=1)\n","\n","    # make two masks to drop flow = 0 at start and rainfall = 0 at the end\n","        masknode = (rainnode.iloc[:, 1:2] == 0).all(axis=1)\n","        start = masknode.loc[~masknode].index[0]\n","        maskrain = (rainnode.iloc[:, 0:1] == 0).all(axis=1)\n","        end = maskrain.loc[~maskrain].index[-1]\n","        mask = (rainnode.index < start) | (rainnode.index > end)\n","        rainnode_masked = rainnode.loc[~mask]\n","        rainlink_masked = rainlink.loc[~mask]\n","        raincap_masked = raincap.loc[~mask]\n","\n","    # process and append data\n","        rainnode_x, rainnode_y = generate_data(rainnode_masked, seq_length_x, seq_length_y, y_start)\n","        rainlink_x, rainlink_y = generate_data(rainlink_masked, seq_length_x, seq_length_y, y_start)\n","        raincap_x, raincap_y = generate_data(raincap_masked, seq_length_x, seq_length_y, y_start)\n","        outx_node.append(rainnode_x)\n","        outy_node.append(rainnode_y)\n","        outx_link.append(rainlink_x)\n","        outy_link.append(rainlink_y)\n","        outx_cap.append(raincap_x)\n","        outy_cap.append(raincap_y)\n","\n","    concat_shuffle_writeintonpz_data(outx_node, outy_node, save_dir_node)\n","    concat_shuffle_writeintonpz_data(outx_link, outy_link, save_dir_link)\n","    concat_shuffle_writeintonpz_data(outx_cap, outy_cap, save_dir_cap)"]},{"cell_type":"markdown","source":["## Generate Training Data\n","### Add the step-ahead rainfall information to evaluate the value of nowcasting.  "],"metadata":{"id":"NbT88_AGXafH"}},{"cell_type":"code","execution_count":4,"metadata":{"id":"zOe04u_XXafQ","executionInfo":{"status":"ok","timestamp":1716040547721,"user_tz":-480,"elapsed":292,"user":{"displayName":"Zhongming Lu","userId":"17616017109863297465"}}},"outputs":[],"source":["def generate_data(raindata_masked, seq_length_x, seq_length_y, y_start):\n","    df_data = raindata_masked.iloc[:,1:-1]\n","    df_rain = raindata_masked.iloc[:,[0, -1]]\n","    num_samples, num_nodes = df_data.shape\n","    data = np.expand_dims(df_data.values, axis=-1)\n","    feature_list = [data]\n","\n","    rain = df_rain.iloc[:,0]\n","    rainfall = np.tile(rain, [1, num_nodes, 1]).transpose((2, 1, 0))\n","    feature_list.append(rainfall)\n","    ##======Add rainfall_30min_head==================\n","    rain_ahead = df_rain.iloc[:,1]\n","    rainfall_ahead = np.tile(rain_ahead,[1, num_nodes, 1]).transpose((2, 1, 0))\n","    feature_list.append(rainfall_ahead)\n","    ##===============================================\n","    data = np.concatenate(feature_list, axis=-1)\n","\n","    x, y = [], []\n","    min_t = abs(min(x_offsets))\n","    max_t = abs(num_samples - abs(max(y_offsets)))\n","    for t in range(min_t, max_t):\n","        x.append(data[t + x_offsets, ...])\n","        y.append(data[t + y_offsets, ...])\n","    x = np.stack(x, axis=0)\n","    y = np.stack(y, axis=0)\n","    return x, y"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"CgMCIZNVXafQ","executionInfo":{"status":"ok","timestamp":1716040566033,"user_tz":-480,"elapsed":327,"user":{"displayName":"Zhongming Lu","userId":"17616017109863297465"}}},"outputs":[],"source":["def concat_shuffle_writeintonpz_data(outx, outy, save_dir):\n","    x_con = np.concatenate(outx, axis=0)\n","    y_con = np.concatenate(outy, axis=0)\n","    permutation = np.random.permutation(x_con.shape[0])\n","    x_data = x_con[permutation]\n","    y_data = y_con[permutation]\n","    num_samples = x_data.shape[0]\n","    num_val = round(num_samples * 0.15)\n","    num_train = round(num_samples * 0.7)\n","    #num_test = round(num_samples * 0.15)# the number of test sample should be the same for different input length, so we dont use this line\n","    num_test = round(599) # this line assign same number of test sample for all input length, 599 is the test sample created by the largest input length, which is a minimum\n","    x_train, y_train = x_data[:num_train], y_data[:num_train]\n","    x_val, y_val = (\n","        x_data[num_train: num_train + num_val],\n","        y_data[num_train: num_train + num_val],\n","    )\n","    x_test, y_test = x_data[-num_test:], y_data[-num_test:]\n","    for cat in [\"train\", \"val\", \"test\"]:\n","        _x, _y = locals()[\"x_\" + cat], locals()[\"y_\" + cat]\n","        print(cat, \"x:\", _x.shape, \"y:\", _y.shape)\n","        file_path = os.path.join(save_dir, f\"{cat}.npz\")\n","        np.savez_compressed(\n","            file_path,\n","            x=_x,\n","            y=_y,\n","            x_offsets=x_offsets.reshape(list(x_offsets.shape) + [1]),\n","            y_offsets=y_offsets.reshape(list(y_offsets.shape) + [1]),\n","        )"]},{"cell_type":"code","source":["#import the rainfall data\n","years = [2020,2021,2022,2023]\n","rainfall_list = []\n","\n","for year in years:\n","  rainfall_file = '/content/drive/MyDrive/GWN-Project/rainfall_climate_data/rainfallkp_'+str(year)+'.txt'\n","  rainfall_list.append(pd.read_csv(rainfall_file, delimiter='\\t'))\n","\n","# Concatenate all rainfall DataFrames into one\n","combined_rainfall = pd.concat(rainfall_list, ignore_index=True)"],"metadata":{"id":"1YzsQF_ebdrh","executionInfo":{"status":"ok","timestamp":1716040575083,"user_tz":-480,"elapsed":4569,"user":{"displayName":"Zhongming Lu","userId":"17616017109863297465"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["#create a new column \"rainfall_30min_ahead\"\n","combined_rainfall['rainfall_30min_ahead'] = combined_rainfall['rainfall'].shift(-30)*6.0"],"metadata":{"id":"8NuYjApr45c5","executionInfo":{"status":"ok","timestamp":1716040577669,"user_tz":-480,"elapsed":314,"user":{"displayName":"Zhongming Lu","userId":"17616017109863297465"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["#convert the 'DateAndTime' to Timestamp\n","combined_rainfall['DateAndTime']=pd.to_datetime(combined_rainfall['DateAndTime'])\n","\n","#change the \"DateAndTime\" to index\n","combined_rainfall.set_index('DateAndTime', inplace=True)\n","\n","#keep the \"rainfall_30min_ahead\" only\n","rainfall_30min_ahead = combined_rainfall['rainfall_30min_ahead']"],"metadata":{"id":"zgXAHttemrQa","executionInfo":{"status":"ok","timestamp":1716040580689,"user_tz":-480,"elapsed":1364,"user":{"displayName":"Zhongming Lu","userId":"17616017109863297465"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716040865805,"user_tz":-480,"elapsed":266755,"user":{"displayName":"Zhongming Lu","userId":"17616017109863297465"}},"outputId":"86993ab0-d6db-46c0-cfcd-9a06a67a336d","id":"u6C_jnMhXafQ"},"outputs":[{"output_type":"stream","name":"stdout","text":["Does the node DataFrame contain any NaN values? True\n","Does the link DataFrame contain any NaN values? True\n","Does the link DataFrame contain any NaN values? True\n","Does the node DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the node DataFrame contain any NaN values? True\n","Does the link DataFrame contain any NaN values? True\n","Does the link DataFrame contain any NaN values? True\n","Does the node DataFrame contain any NaN values? True\n","Does the link DataFrame contain any NaN values? True\n","Does the link DataFrame contain any NaN values? True\n","Does the node DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the node DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the node DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the node DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the node DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the node DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the node DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the node DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the node DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the node DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the node DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the node DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the node DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the node DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the node DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the node DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the node DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the node DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the node DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the node DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the node DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the node DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the node DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the node DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the node DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the node DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the node DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the node DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the node DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the node DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the node DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the node DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the node DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the node DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the node DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the node DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the node DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the node DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the node DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","train x: (3016, 6, 664, 3) y: (3016, 6, 664, 3)\n","val x: (646, 6, 664, 3) y: (646, 6, 664, 3)\n","test x: (599, 6, 664, 3) y: (599, 6, 664, 3)\n","train x: (3016, 6, 667, 3) y: (3016, 6, 667, 3)\n","val x: (646, 6, 667, 3) y: (646, 6, 667, 3)\n","test x: (599, 6, 667, 3) y: (599, 6, 667, 3)\n","train x: (3016, 6, 667, 3) y: (3016, 6, 667, 3)\n","val x: (646, 6, 667, 3) y: (646, 6, 667, 3)\n","test x: (599, 6, 667, 3) y: (599, 6, 667, 3)\n"]}],"source":["#seq_lengths = [(6, 6), (7, 6), (8, 6), (9, 6),(10, 6), (11, 6),(12, 6), (13, 6),(14, 6)]\n","seq_lengths = [(6, 6)]\n","\n","for seq_length_x, seq_length_y in seq_lengths:\n","    y_start = 1\n","    x_offsets = np.sort(np.concatenate((np.arange(-(seq_length_x - 1), 1, 1),)))\n","    y_offsets = np.sort(np.arange(y_start, (seq_length_y + 1), 1))\n","\n","    save_dir_link = \"/content/drive/MyDrive/GWN-Project/dataset/link/\"+\"link_flow_len\" + str(seq_length_x) +\"_\" + str(seq_length_y) +\"_f_r\"\n","    save_dir_node = \"/content/drive/MyDrive/GWN-Project/dataset/node/\"+\"node_flow_len\" + str(seq_length_x) +\"_\" + str(seq_length_y) +\"_f_r\"\n","    save_dir_cap = \"/content/drive/MyDrive/GWN-Project/dataset/cap/\"+\"link_cap_len\" + str(seq_length_x) +\"_\" + str(seq_length_y) +\"_f_r\"\n","    #os.makedirs(save_dir_link)\n","    #os.makedirs(save_dir_node)\n","    #os.makedirs(save_dir_cap)\n","\n","    outx_node=[]\n","    outy_node=[]\n","    outx_link=[]\n","    outy_link=[]\n","    outx_cap=[]\n","    outy_cap=[]\n","\n","    file_names = ['2021/event64','2020/event37','2021/event29','2022/event38','2022/event51','2023/event15','2021/event41',\n","                  '2020/event60','2023/event8','2022/event6','2023/event1','2022/event31','2023/event16','2020/event67',\n","                  '2021/event19','2020/event55','2021/event25','2021/event22','2022/event27','2023/event19','2021/event37',\n","                  '2022/event28','2022/event26','2021/event7','2022/event47','2022/event36','2021/event5','2021/event46',\n","                  '2022/event34','2020/event61','2020/event69','2021/event50','2021/event12','2022/event29','2022/event46',\n","                  '2023/event4','2020/event36','2020/event49','2022/event8','2021/event31','2022/event33','2021/event32',\n","                  '2021/event56']\n","\n","    #For code preparing only\n","    #file_names = ['2020/event36']\n","\n","    for file in file_names:\n","    # read out file\n","        out = read_out_file('/content/drive/MyDrive/GWN-Project/events/'+file +'.out')\n","        type(out.to_numpy())\n","        out.to_frame()\n","\n","    # extract rainfall, node, link,cap and concat them\n","        rainfall = out.get_part('system', '', 'rainfall')\n","        node = out.get_part('node',out.labels['node'],'total_inflow')\n","        link = out.get_part('link',out.labels['link'],'flow')\n","        cap = out.get_part('link',out.labels['link'],'capacity')\n","        rainnode = pd.concat([rainfall, node], axis=1)\n","        rainlink = pd.concat([rainfall, link], axis=1)\n","        raincap = pd.concat([rainfall, cap], axis=1)\n","\n","    # make two masks to drop flow = 0 at start and rainfall = 0 at the end\n","        masknode = (rainnode.iloc[:, 1:2] == 0).all(axis=1)\n","        start = masknode.loc[~masknode].index[0]\n","        maskrain = (rainnode.iloc[:, 0:1] == 0).all(axis=1)\n","        end = maskrain.loc[~maskrain].index[-1]\n","        mask = (rainnode.index < start) | (rainnode.index > end)\n","        rainnode_masked = rainnode.loc[~mask]\n","        rainlink_masked = rainlink.loc[~mask]\n","        raincap_masked = raincap.loc[~mask]\n","\n","    # attach a new column of 30min ahead shifted up (rainfall information)\n","        rainnode_masked = pd.merge(rainnode_masked, rainfall_30min_ahead, left_index=True, right_index=True, how='left')\n","        rainlink_masked = pd.merge(rainlink_masked, rainfall_30min_ahead, left_index=True, right_index=True, how='left')\n","        raincap_masked = pd.merge(raincap_masked, rainfall_30min_ahead, left_index=True, right_index=True, how='left')\n","\n","    # check if there are any NaN values in the DataFrame\n","        has_nans_node = rainnode_masked.isna().any().any()\n","        print(\"Does the node DataFrame contain any NaN values?\", has_nans_node)\n","\n","        has_nans_link = rainlink_masked.isna().any().any()\n","        print(\"Does the link DataFrame contain any NaN values?\", has_nans_link)\n","\n","        has_nans_cap = raincap_masked.isna().any().any()\n","        print(\"Does the link DataFrame contain any NaN values?\", has_nans_cap)\n","\n","    # Remove rows where any cell has NaN\n","        rainnode_masked = rainnode_masked.dropna()\n","        rainlink_masked = rainlink_masked.dropna()\n","        raincap_masked = raincap_masked.dropna()\n","\n","    # process and append data\n","        rainnode_x, rainnode_y = generate_data(rainnode_masked, seq_length_x, seq_length_y, y_start)\n","        rainlink_x, rainlink_y = generate_data(rainlink_masked, seq_length_x, seq_length_y, y_start)\n","        raincap_x, raincap_y = generate_data(raincap_masked, seq_length_x, seq_length_y, y_start)\n","        outx_node.append(rainnode_x)\n","        outy_node.append(rainnode_y)\n","        outx_link.append(rainlink_x)\n","        outy_link.append(rainlink_y)\n","        outx_cap.append(raincap_x)\n","        outy_cap.append(raincap_y)\n","\n","    concat_shuffle_writeintonpz_data(outx_node, outy_node, save_dir_node)\n","    concat_shuffle_writeintonpz_data(outx_link, outy_link, save_dir_link)\n","    concat_shuffle_writeintonpz_data(outx_cap, outy_cap, save_dir_cap)"]},{"cell_type":"code","source":["# check if there are any NaN values in the DataFrame\n","has_nans_node = rainnode_masked.isna().any().any()\n","print(\"Does the node DataFrame contain any NaN values?\", has_nans_node)\n","\n","has_nans_link = rainlink_masked.isna().any().any()\n","print(\"Does the link DataFrame contain any NaN values?\", has_nans_link)\n","\n","has_nans_cap = raincap_masked.isna().any().any()\n","print(\"Does the link DataFrame contain any NaN values?\", has_nans_cap)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PeQ_xzouAPc2","executionInfo":{"status":"ok","timestamp":1716040880494,"user_tz":-480,"elapsed":314,"user":{"displayName":"Zhongming Lu","userId":"17616017109863297465"}},"outputId":"00ed4c1a-799a-457d-8bad-d339fe21c706"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Does the node DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n","Does the link DataFrame contain any NaN values? False\n"]}]}],"metadata":{"colab":{"provenance":[],"collapsed_sections":["70iYjG0jWqGz","tjF-gNJDMJwn","nt0dWFQrMRiG"],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}